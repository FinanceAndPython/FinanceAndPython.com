{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas \n",
    "\n",
    "Pandas is one of the most powerful data science libraries in python. It allows you to work with datasets to quickly run computations, organize data and apply functions to it. The biggest benefit of pandas is the speed. While running things like loops in native python can take much longer than other languages such as C++, pandas bridges the gap to make functions run extremely fast. It is done by converting code to C++ which can run at a much faster speed. In this first lesson we will explore some of the most basic elements of pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Series\n",
    "\n",
    "In regular python, we have a list which holds one dimensional data for us. With pandas, there is the series data type which is similar except that there is also an index (which can be different then the usual 0, 1, 2, etc. index) and as well there are many more pandas functions that we can use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with our basic list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In regular python we have a list\n",
    "l = [1,2,3,4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n",
      "5    6\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Create a pandas series by passing the list\n",
    "s = pd.Series(l)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A few things to notice. On the left side is the index which automatically defaults to an integer index starting at 0. On the right are the values. As well, it says dtype which is just to say what kind of data is held within the series. Pandas automatically noticed we only had integers so it assigned the dtype of int64."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying an Index\n",
    "\n",
    "We don't have to default to the normal index. If we pass in the argument index when creating our series it will be reflected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "e    5\n",
      "f    6\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Create a series with a custom index\n",
    "s = pd.Series(l,index=[\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we see that the left hand side is now our index of letters. We can also a set an index after the fact by setting the index attribute. For example if we created our series without an index we can change it after like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "d    4\n",
      "e    5\n",
      "f    6\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Create the series\n",
    "s = pd.Series(l)\n",
    "\n",
    "#Set the index\n",
    "s.index=[\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"]\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One benefit of pandas is that we can easily apply math functions to it instead of iterating over every element. For example, the code below will square each value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a     1\n",
      "b     4\n",
      "c     9\n",
      "d    16\n",
      "e    25\n",
      "f    36\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Square all the values\n",
    "s = s ** 2\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want just the values in the series, we can use the values attribute. The format we will get back is a numpy array which we will cover more in future lessons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  4  9 16 25 36]\n"
     ]
    }
   ],
   "source": [
    "#Get the values of the series\n",
    "print(s.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing\n",
    "\n",
    "Indexing can be done two different ways. If you use iloc, you can index similar to how one might index a list. With loc you can instead index based on the index values. If you do this it will include everything up to and including the last index. First, let's use iloc to get the first three values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    4\n",
      "c    9\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Get the first three values\n",
    "print(s.iloc[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using loc we can also do this by passing a and c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    4\n",
      "c    9\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(s.loc['a':'c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas DataFrames\n",
    "\n",
    "A pandas dataframe is a structure which holds 2 dimensional data including an index and columns. You can think of it is similar to a spreadsheet. To create one, you need to pass in a list of either tuples, list of lists or (we won't cover it here) a dictionary. For our first dataframe, let's get the following data. Each entry of the list below is going to be 4 attributes, a name, a height, a weight and a string for offense or defense. Right now these are all strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Ray Lewis', \"6'1\", '250', 'Defense'), ('Tom Brady', \"6'4\", '225', 'Offense'), ('Julio Jones', \"6'3\", '220', 'Offense'), ('Richard Sherman', \"6'3\", '194', 'Defense')]\n"
     ]
    }
   ],
   "source": [
    "#Now, let's create some data, each element corresponds to a row\n",
    "#Each tuple corresponds to the data for the row\n",
    "data = []\n",
    "data.append((\"Ray Lewis\",\"6'1\",\"250\",\"Defense\"))\n",
    "data.append((\"Tom Brady\",\"6'4\",\"225\",\"Offense\"))\n",
    "data.append((\"Julio Jones\",\"6'3\",\"220\",\"Offense\"))\n",
    "data.append((\"Richard Sherman\",\"6'3\",\"194\",\"Defense\"))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 0    1    2        3\n",
      "0        Ray Lewis  6'1  250  Defense\n",
      "1        Tom Brady  6'4  225  Offense\n",
      "2      Julio Jones  6'3  220  Offense\n",
      "3  Richard Sherman  6'3  194  Defense\n"
     ]
    }
   ],
   "source": [
    "#We can initialize a dataframe with a list of data\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pass in a list of labels for either the columns or index if you want. For our example from before we can add columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Name Height Weight     Type\n",
      "0        Ray Lewis    6'1    250  Defense\n",
      "1        Tom Brady    6'4    225  Offense\n",
      "2      Julio Jones    6'3    220  Offense\n",
      "3  Richard Sherman    6'3    194  Defense\n"
     ]
    }
   ],
   "source": [
    "#The columns argument lets us set the names for the columns in our dataframe\n",
    "df = pd.DataFrame(data,columns=[\"Name\",\"Height\",\"Weight\",\"Type\"])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findinding column values can be done in the same way that you might grab values from a dictionary. You pass in brackets with the column you want to grab. For example, the following will get you the names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          Ray Lewis\n",
      "1          Tom Brady\n",
      "2        Julio Jones\n",
      "3    Richard Sherman\n",
      "Name: Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#To get a specific column, we index with the column name.\n",
    "print(df[\"Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    6'1\n",
      "1    6'4\n",
      "2    6'3\n",
      "3    6'3\n",
      "Name: Height, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Likewise we can get height\n",
    "print(df[\"Height\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we give a nested list where the first element is a list of names, we can select multiple columns. This will give us back a dataframe which is just with the columns we are looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Name Weight\n",
      "0        Ray Lewis    250\n",
      "1        Tom Brady    225\n",
      "2      Julio Jones    220\n",
      "3  Richard Sherman    194\n"
     ]
    }
   ],
   "source": [
    "#Grab the name and weight columns\n",
    "print(df[[\"Name\",\"Weight\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By indexing into a column but then passing values we can either overwrite or create a new column. Below we are able to set the retired column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Name Height Weight     Type  Retired\n",
      "0        Ray Lewis    6'1    250  Defense     True\n",
      "1        Tom Brady    6'4    225  Offense    False\n",
      "2      Julio Jones    6'3    220  Offense    False\n",
      "3  Richard Sherman    6'3    194  Defense    False\n"
     ]
    }
   ],
   "source": [
    "#We can also assign a new column by the above method if we give a list of equal length as the dataframes rows\n",
    "df[\"Retired\"] = [True,False,False,False]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply\n",
    "\n",
    "By using apply you can use apply a function to each element of a column or every row/every column. To begin with let's define a function which will deal with the height column. The issue with height is that it is a string representation right now and we might want an actual numeric representation. Let's do it piece by piece. Start with the height of the first player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6'1\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "#Get the first player's height\n",
    "height = df.loc[0, \"Height\"]\n",
    "\n",
    "#Print the value and the type\n",
    "print(height)\n",
    "print(type(height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do would be to grab the two pieces of information that this string provides, the feet and inches. If we use split and split on \"'\", we can grab the two pieces as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6', '1']\n"
     ]
    }
   ],
   "source": [
    "#Split in two\n",
    "height = height.split(\"'\")\n",
    "print(height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have strings in both of these cases, so we are going to want to convert them both to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 1]\n"
     ]
    }
   ],
   "source": [
    "#Convert to integers\n",
    "height = [int(x) for x in height]\n",
    "print(height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the value on the left is the number of feet, the number on the right is the number of inches. Let's convert the left number to be the number of inches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72, 1]\n"
     ]
    }
   ],
   "source": [
    "#Convert the feet to inches\n",
    "height[0] = height[0] * 12\n",
    "print(height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, sum these two numbers and we have the height in terms of total inches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n"
     ]
    }
   ],
   "source": [
    "#Get the total height in inches\n",
    "height = sum(height)\n",
    "print(height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know all the steps, we can convert this into a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n"
     ]
    }
   ],
   "source": [
    "def height_convert(height):\n",
    "    #Split in two\n",
    "    height = height.split(\"'\")\n",
    "    \n",
    "    #Convert to integers\n",
    "    height = [int(x) for x in height]\n",
    "    \n",
    "    #Convert the feet to inches\n",
    "    height[0] = height[0] * 12\n",
    "    \n",
    "    #Get the total height in inches\n",
    "    height = sum(height)\n",
    "    return height\n",
    "print(height_convert(\"6'1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using apply on a column, you index into the column, call apply, then pass along the function which you want to apply. This assumes that only one argument is needed. This will return a new series where the values are the returned values from the function applied to every value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    73\n",
      "1    76\n",
      "2    75\n",
      "3    75\n",
      "Name: Height, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Apply our new function\n",
    "print(df[\"Height\"].apply(height_convert))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's overwrite our prior height column with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Name  Height Weight     Type  Retired\n",
      "0        Ray Lewis      73    250  Defense     True\n",
      "1        Tom Brady      76    225  Offense    False\n",
      "2      Julio Jones      75    220  Offense    False\n",
      "3  Richard Sherman      75    194  Defense    False\n"
     ]
    }
   ],
   "source": [
    "#Modify the values\n",
    "df[\"Height\"] = df[\"Height\"].apply(height_convert)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might want to see weight divided by height but trying that will cause an error because height is in string representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda/envs/FinanceAndPython/lib/python3.8/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mna_arithmetic_op\u001b[0;34m(left, right, op, str_rep)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr_rep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/FinanceAndPython/lib/python3.8/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(op, op_str, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/FinanceAndPython/lib/python3.8/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-7d5eb8d3736d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#If we try to divide here we will run into an issue, weight is still a string representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Weight\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Height\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/envs/FinanceAndPython/lib/python3.8/site-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/FinanceAndPython/lib/python3.8/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(left, right)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0mlvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0mrvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr_rep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/FinanceAndPython/lib/python3.8/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op, str_rep)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_arithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr_rep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/FinanceAndPython/lib/python3.8/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mna_arithmetic_op\u001b[0;34m(left, right, op, str_rep)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr_rep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasked_arith_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_fill_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/FinanceAndPython/lib/python3.8/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mmasked_arith_op\u001b[0;34m(x, y, op)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxrav\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myrav\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "#If we try to divide here we will run into an issue, weight is still a string representation\n",
    "print(df[\"Weight\"]/df[\"Height\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see what types we have for each column, we can call dtypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name       object\n",
      "Height      int64\n",
      "Weight     object\n",
      "Type       object\n",
      "Retired      bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#The dtypes attribute lets us see the attribute\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For conversion to numeric values, there are two options. One is that we can say astype() and pass in a type. If we pass in integer than we can convert a column to integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name       object\n",
      "Height      int64\n",
      "Weight      int64\n",
      "Type       object\n",
      "Retired      bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Convert to integer\n",
    "df[\"Weight\"] = df[\"Weight\"].astype(int)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other option is to call pd.to_numeric and pass in the series. If these were floating point numbers, it would automatically convert to that instead, but in this case they are all integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name       object\n",
      "Height      int64\n",
      "Weight      int64\n",
      "Type       object\n",
      "Retired      bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Also converts to numeric values\n",
    "df[\"Weight\"] = pd.to_numeric(df[\"Weight\"])\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have numeric types we can do mathematical operations with the columns. To divide weight by height, we can do this below...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3.424658\n",
      "1    2.960526\n",
      "2    2.933333\n",
      "3    2.586667\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Find the ratio of weight and height\n",
    "print(df[\"Weight\"]/df[\"Height\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean Indexing\n",
    "\n",
    "Sometimes you want to grab only certain rows based on some sort of comparison. This is the purpose of boolean indexing. What it allows you to do is check a comparison then return only those rows that are true for the comparison. To begin with let's define a list of boolean values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a boolean index\n",
    "bool_index = [True, False, True, False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you pass in a boolean index to the dataframe the same way that you pass in columns it will filter to only true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Name  Height  Weight     Type  Retired\n",
      "0    Ray Lewis      73     250  Defense     True\n",
      "2  Julio Jones      75     220  Offense    False\n"
     ]
    }
   ],
   "source": [
    "print(df[bool_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice above that we only got back the first and third row! Of course you would get the same by inputting it the manual way like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Name  Height  Weight     Type  Retired\n",
      "0    Ray Lewis      73     250  Defense     True\n",
      "2  Julio Jones      75     220  Offense    False\n"
     ]
    }
   ],
   "source": [
    "print(df[[True,False,True,False]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if wanted to find out which players are over 220 pounds and return only those players. The first step is to get our boolean index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     True\n",
      "1     True\n",
      "2    False\n",
      "3    False\n",
      "Name: Weight, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#We can also check the truth of a statement such as which rows have weight values over 220\n",
    "print(df[\"Weight\"] > 220)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with that it is easy to filter to the correct rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Name  Height  Weight     Type  Retired\n",
      "0  Ray Lewis      73     250  Defense     True\n",
      "1  Tom Brady      76     225  Offense    False\n"
     ]
    }
   ],
   "source": [
    "#And this allows us to filter based on an argument. In this case we can print only rows with weights over 220\n",
    "print(df[df[\"Weight\"]>220])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Dataframes\n",
    "\n",
    "Often we will have data from multiple sources and will need to combine them together to create a dataframe with all data together. For an example, we can first make a second set of data. Something you will notice is that there are a few values set to none. This happens really often when working with data. Sometimes a field can't be measured 100% of the time or does not apply so it has the value of none instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Name  Height  Weight     Type  Retired\n",
      "0       Allen Robinson    75.0   250.0  Offense    False\n",
      "1         Alvin Kamara     NaN   215.0  Offense    False\n",
      "2  Christian McCaffrey    71.0     NaN  Offense    False\n"
     ]
    }
   ],
   "source": [
    "#Let's create a second set of data\n",
    "\n",
    "data = []\n",
    "data.append((\"Allen Robinson\",75,250,\"Offense\",False))\n",
    "data.append((\"Alvin Kamara\",None,215,\"Offense\",False))\n",
    "data.append((\"Christian McCaffrey\",71,None,\"Offense\",False))\n",
    "\n",
    "#And turn it into a second dataframe\n",
    "#You'll notice some data is missing, this happens commonly working with real data\n",
    "df2 = pd.DataFrame(data,columns=[\"Name\",\"Height\",\"Weight\",\"Type\",\"Retired\"])\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function pd.concat takes a list of dataframes to put together. By default they will be appended vertically, but you can change this behavior by using the axis keyword. The code below will take the two dataframes and put them together to make a new combined dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Name  Height  Weight     Type  Retired\n",
      "0            Ray Lewis    73.0   250.0  Defense     True\n",
      "1            Tom Brady    76.0   225.0  Offense    False\n",
      "2          Julio Jones    75.0   220.0  Offense    False\n",
      "3      Richard Sherman    75.0   194.0  Defense    False\n",
      "0       Allen Robinson    75.0   250.0  Offense    False\n",
      "1         Alvin Kamara     NaN   215.0  Offense    False\n",
      "2  Christian McCaffrey    71.0     NaN  Offense    False\n"
     ]
    }
   ],
   "source": [
    "#The pd.concat() function lets us put together dataframes\n",
    "df_final = pd.concat([df,df2])\n",
    "print(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset the Index\n",
    "\n",
    "If you look at the index above you see that they actually overlap. Sometimes this is the behavior you might want, but often you want to set the index to be a new unique integer index. To do this we can call reset_index. This will return a new dataframe which has the old index kept as a column added to the dataframe as well as the new index from 0 to N-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index                 Name  Height  Weight     Type  Retired\n",
      "0      0            Ray Lewis    73.0   250.0  Defense     True\n",
      "1      1            Tom Brady    76.0   225.0  Offense    False\n",
      "2      2          Julio Jones    75.0   220.0  Offense    False\n",
      "3      3      Richard Sherman    75.0   194.0  Defense    False\n",
      "4      0       Allen Robinson    75.0   250.0  Offense    False\n",
      "5      1         Alvin Kamara     NaN   215.0  Offense    False\n",
      "6      2  Christian McCaffrey    71.0     NaN  Offense    False\n"
     ]
    }
   ],
   "source": [
    "#The two dataframes have indexes that overlap! We could fix this by resetting the index, as so....\n",
    "print(df_final.reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you give the argument ignore_index=True then the old index will simply be dropped from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Name  Height  Weight     Type  Retired\n",
      "0            Ray Lewis    73.0   250.0  Defense     True\n",
      "1            Tom Brady    76.0   225.0  Offense    False\n",
      "2          Julio Jones    75.0   220.0  Offense    False\n",
      "3      Richard Sherman    75.0   194.0  Defense    False\n",
      "4       Allen Robinson    75.0   250.0  Offense    False\n",
      "5         Alvin Kamara     NaN   215.0  Offense    False\n",
      "6  Christian McCaffrey    71.0     NaN  Offense    False\n"
     ]
    }
   ],
   "source": [
    "#Or we can give the argument ignore_index=True to reset it during the concat function\n",
    "df_final = pd.concat([df,df2],ignore_index=True)\n",
    "print(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Null Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you come across null values there are a few options of what you can do. One option is to simply drop any rows which have null values. The function dropna() achieves this by going through every row and ensuring there are no null values. It will not do it in place but rather returns a new version of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Name  Height  Weight     Type  Retired\n",
      "0        Ray Lewis    73.0   250.0  Defense     True\n",
      "1        Tom Brady    76.0   225.0  Offense    False\n",
      "2      Julio Jones    75.0   220.0  Offense    False\n",
      "3  Richard Sherman    75.0   194.0  Defense    False\n",
      "4   Allen Robinson    75.0   250.0  Offense    False\n"
     ]
    }
   ],
   "source": [
    "#The dropna() function gets rid of any rows with missing values\n",
    "print(df_final.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are only some columns that you want to consider when dropping null values you can give the keyword subset which will only consider dropping rows with null values in these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Name  Height  Weight     Type  Retired\n",
      "0            Ray Lewis    73.0   250.0  Defense     True\n",
      "1            Tom Brady    76.0   225.0  Offense    False\n",
      "2          Julio Jones    75.0   220.0  Offense    False\n",
      "3      Richard Sherman    75.0   194.0  Defense    False\n",
      "4       Allen Robinson    75.0   250.0  Offense    False\n",
      "6  Christian McCaffrey    71.0     NaN  Offense    False\n"
     ]
    }
   ],
   "source": [
    "#If given an argument subset, we can drop only rows with missing values from the subset \n",
    "print(df_final.dropna(subset=[\"Height\",\"Type\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not want to return a dataframe but want to instead modify the one you are calling these functions on you are free to use the argument inplace=True. This will make it so that the modification happens to the object you passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Name  Height  Weight     Type  Retired\n",
      "0            Ray Lewis    73.0   250.0  Defense     True\n",
      "1            Tom Brady    76.0   225.0  Offense    False\n",
      "2          Julio Jones    75.0   220.0  Offense    False\n",
      "3      Richard Sherman    75.0   194.0  Defense    False\n",
      "4       Allen Robinson    75.0   250.0  Offense    False\n",
      "6  Christian McCaffrey    71.0     NaN  Offense    False\n"
     ]
    }
   ],
   "source": [
    "#If we use inplace=True then the dropna function happens in place\n",
    "df_final.dropna(inplace=True,subset=[\"Height\",\"Type\"])\n",
    "print(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may also prefer to use a more descriptive index like the name of the player to refer to the different rows. Calling set_index will return a new dataframe with the index set to whatever column you passed it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Height  Weight     Type  Retired\n",
      "Name                                                 \n",
      "Ray Lewis              73.0   250.0  Defense     True\n",
      "Tom Brady              76.0   225.0  Offense    False\n",
      "Julio Jones            75.0   220.0  Offense    False\n",
      "Richard Sherman        75.0   194.0  Defense    False\n",
      "Allen Robinson         75.0   250.0  Offense    False\n",
      "Christian McCaffrey    71.0     NaN  Offense    False\n"
     ]
    }
   ],
   "source": [
    "#Setting the index to name changes it from a column to index\n",
    "df_final = df_final.set_index(\"Name\")\n",
    "print(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is new data that has come to light, you have the option of overwriting data using loc. For example, we can overwrite the row for Christian McCaffrey and the weight value in that row by executing the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Height  Weight     Type  Retired\n",
      "Name                                                 \n",
      "Ray Lewis              73.0   250.0  Defense     True\n",
      "Tom Brady              76.0   225.0  Offense    False\n",
      "Julio Jones            75.0   220.0  Offense    False\n",
      "Richard Sherman        75.0   194.0  Defense    False\n",
      "Allen Robinson         75.0   250.0  Offense    False\n",
      "Christian McCaffrey    71.0   205.0  Offense    False\n"
     ]
    }
   ],
   "source": [
    "#Using loc we can overwrite data\n",
    "df_final.loc[\"Christian McCaffrey\",\"Weight\"] = 205\n",
    "print(df_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
